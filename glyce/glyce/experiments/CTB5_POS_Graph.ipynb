{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CTB5_POS_Graph.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"z2Id0h3kTG5F","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a6c54796-6017-4b26-e725-43016ed5c39a"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mLzXIwx9WI9f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2c0f6264-763e-4f17-f6c5-28fd15ebf45e"},"source":["!pip install pypinyin pywubi zhconv overrides boto3\n","!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-geometric"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pypinyin\n","  Downloading pypinyin-0.42.0-py2.py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 8.4 MB/s \n","\u001b[?25hCollecting pywubi\n","  Downloading pywubi-0.0.2-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 68.1 MB/s \n","\u001b[?25hCollecting zhconv\n","  Downloading zhconv-1.4.2.tar.gz (183 kB)\n","\u001b[K     |████████████████████████████████| 183 kB 89.5 MB/s \n","\u001b[?25hCollecting overrides\n","  Downloading overrides-6.1.0-py3-none-any.whl (14 kB)\n","Collecting boto3\n","  Downloading boto3-1.18.25-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 65.2 MB/s \n","\u001b[?25hCollecting typing-utils>=0.0.3\n","  Downloading typing_utils-0.1.0-py3-none-any.whl (10 kB)\n","Collecting botocore<1.22.0,>=1.21.25\n","  Downloading botocore-1.21.25-py3-none-any.whl (7.8 MB)\n","\u001b[K     |████████████████████████████████| 7.8 MB 77.4 MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 9.5 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.25->boto3) (2.8.2)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 73.6 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.25->boto3) (1.15.0)\n","Building wheels for collected packages: zhconv\n","  Building wheel for zhconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for zhconv: filename=zhconv-1.4.2-py2.py3-none-any.whl size=181081 sha256=2e57aa3997584b6c0f5c721090329ff9fa13aed65a8c2b11404d9497f5569ad6\n","  Stored in directory: /root/.cache/pip/wheels/10/31/84/fca23def9be1db201eeaa76f4ee50a7d64f6e20ee7b223cc4f\n","Successfully built zhconv\n","Installing collected packages: urllib3, jmespath, botocore, typing-utils, s3transfer, zhconv, pywubi, pypinyin, overrides, boto3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.6 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.18.25 botocore-1.21.25 jmespath-0.10.0 overrides-6.1.0 pypinyin-0.42.0 pywubi-0.0.2 s3transfer-0.5.0 typing-utils-0.1.0 urllib3-1.26.6 zhconv-1.4.2\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-scatter\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_scatter-2.0.8-cp37-cp37m-linux_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 7.8 MB/s \n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.0.8\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-sparse\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_sparse-0.6.11-cp37-cp37m-linux_x86_64.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 7.6 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.6.11\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-cluster\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (926 kB)\n","\u001b[K     |████████████████████████████████| 926 kB 6.8 MB/s \n","\u001b[?25hInstalling collected packages: torch-cluster\n","Successfully installed torch-cluster-1.5.9\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-spline-conv\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (382 kB)\n","\u001b[K     |████████████████████████████████| 382 kB 7.0 MB/s \n","\u001b[?25hInstalling collected packages: torch-spline-conv\n","Successfully installed torch-spline-conv-1.2.1\n","Collecting torch-geometric\n","  Downloading torch_geometric-1.7.2.tar.gz (222 kB)\n","\u001b[K     |████████████████████████████████| 222 kB 7.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.2)\n","Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.15)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n","Collecting rdflib\n","  Downloading rdflib-6.0.0-py3-none-any.whl (376 kB)\n","\u001b[K     |████████████████████████████████| 376 kB 65.5 MB/s \n","\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.4.7)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n","Collecting isodate\n","  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n","\u001b[K     |████████████████████████████████| 45 kB 4.5 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 88.6 MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-1.7.2-py3-none-any.whl size=388143 sha256=beb32f5f75389880040b1df615fec6488edcbc251742f75ff2b516fc64edd8e4\n","  Stored in directory: /root/.cache/pip/wheels/55/93/b6/2eeb0465afe89aee74d7a07a606e9770466d7565abd45a99d5\n","Successfully built torch-geometric\n","Installing collected packages: urllib3, isodate, rdflib, torch-geometric\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.26.6\n","    Uninstalling urllib3-1.26.6:\n","      Successfully uninstalled urllib3-1.26.6\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed isodate-0.6.0 rdflib-6.0.0 torch-geometric-1.7.2 urllib3-1.25.11\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Oob8oexy_N4","outputId":"a26b1634-7738-4f72-aad8-a6e022a0e6bd"},"source":["import time\n","import torch\n","print(torch.__version__)\n","print(torch.cuda.get_device_name(0))\n","start = time.perf_counter()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.9.0+cu102\n","Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AxJvcOtUTLkH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"645cf322-6ab1-4725-f89a-16fb5cd5a993"},"source":["!python3 \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/bin/run_bert_graph_tagger.py\" \\\n","--data_sign ctb5_pos \\\n","--task_name pos \\\n","--config_path \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/configs/graph_bert.json\" \\\n","--data_dir \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/pos/ctb5\" \\\n","--output_name \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/my_export_models/ctb5_pos graph.bin\" \\\n","--bert_model \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\" \\\n","--graph_path \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/graphsDictOrder.pickle\" \\\n","--checkpoint 1150 \\\n","--seed 8008 \\\n","--max_seq_length 150 \\\n","--do_train \\\n","--do_eval \\\n","--train_batch_size 24 \\\n","--dev_batch_size 24 \\\n","--test_batch_size 24 \\\n","--learning_rate 3e-5 \\\n","--num_train_epochs 15 \\\n","--gcn_hidden 300 \\\n","--k 30 \\\n","--graph_embsize 24 \\\n","--output_size 24 \\\n","--pooler_fc_size 792 \\\n","--hidden_size 792 \\\n","--transformer_hidden_size 792 \\\n","--num_features 6 \\\n","--warmup_proportion 0 \\\n","--batch_norm \"layer\" \\\n","--pretrained_graph \"yes\" \\\n","--graph_dict \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/unsupGraphModelDict300.bin\" \\\n","--training_strat \"bert-glyce-joint\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce\n","PATH to render.py\n","=*=*=*=*=*=*=*=*=*=*\n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce\n","PRINT default FONT PATH\n","********************\n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/fonts\n","********************\n","Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","Please Notice that Merge the args_dict and json_config ... ... \n","Update the config from args input\n","Update the config from args input\n","{\n","  \"glyph_ratio\": 0.1,\n","  \"glyph_decay\": 0.1,\n","  \"glyph_warmup\": 0,\n","  \"bert_frozen\": \"true\",\n","  \"hidden_size\": 792,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"classifier_sign\": \"multi_nonlinear\",\n","  \"clip_grad\": 1.0,\n","  \"bert_config\": {\n","    \"attention_probs_dropout_prob\": 0.1,\n","    \"directionality\": \"bidi\",\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.1,\n","    \"hidden_size\": 768,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"max_position_embeddings\": 512,\n","    \"num_attention_heads\": 12,\n","    \"num_hidden_layers\": 12,\n","    \"pooler_fc_size\": 768,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 3,\n","    \"pooler_size_per_head\": 128,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"type_vocab_size\": 2,\n","    \"vocab_size\": 21128\n","  },\n","  \"graph_config\": {\n","    \"hidden_dropout_prob\": 0.5,\n","    \"max_position_embeddings\": 512,\n","    \"bert_model\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\",\n","    \"graph_path\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/graphsDictOrder.pickle\",\n","    \"char2word_dim\": 0,\n","    \"char_drop\": 0.5,\n","    \"char_embsize\": 0,\n","    \"gcn_dropout\": 0.5,\n","    \"dropout\": 0.5,\n","    \"num_features\": 6,\n","    \"gcn_hidden\": 300,\n","    \"k\": 30,\n","    \"gcn_layer\": \"SAGE\",\n","    \"fc_merge\": false,\n","    \"font_channels\": 1,\n","    \"font_name\": \"cjk/NotoSansCJKsc-Regular.otf\",\n","    \"font_normalize\": false,\n","    \"font_size\": 18,\n","    \"graph_cnn_type\": \"Yuxian8\",\n","    \"graph_embsize\": 24,\n","    \"graph_groups\": 8,\n","    \"idx2char\": null,\n","    \"idx2word\": null,\n","    \"level\": \"char\",\n","    \"loss_mask_ids\": [\n","      0,\n","      101,\n","      102\n","    ],\n","    \"num_fonts_concat\": 1,\n","    \"output_size\": 24,\n","    \"pretrained_char_embedding\": \"\",\n","    \"pretrained_word_embedding\": \"\",\n","    \"random_erase\": false,\n","    \"random_fonts\": 0,\n","    \"subchar_embsize\": 512,\n","    \"subchar_type\": \"\",\n","    \"use_batch_norm\": true,\n","    \"use_highway\": false,\n","    \"use_layer_norm\": false,\n","    \"use_maxpool\": true,\n","    \"use_traditional\": false,\n","    \"word_embsize\": 1024,\n","    \"yuxian_merge\": false,\n","    \"pool\": \"sort\",\n","    \"graph_dict\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/unsupGraphModelDict300.bin\",\n","    \"pretrained_graph\": \"yes\",\n","    \"batch_norm\": \"layer\"\n","  },\n","  \"transformer_config\": {\n","    \"max_position_embeddings\": 512,\n","    \"attention_probs_dropout_prob\": 0.5,\n","    \"directionality\": \"bidi\",\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.5,\n","    \"hidden_size\": 792,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 6144,\n","    \"num_attention_heads\": 24,\n","    \"num_hidden_layers\": 2,\n","    \"pooler_fc_size\": 792,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 2,\n","    \"pooler_size_per_head\": 256,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"type_vocab_size\": 2,\n","    \"vocab_size\": 21128\n","  },\n","  \"config_path\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/configs/graph_bert.json\",\n","  \"data_dir\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/pos/ctb5\",\n","  \"bert_model\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\",\n","  \"task_name\": \"pos\",\n","  \"cuda\": true,\n","  \"max_seq_length\": 150,\n","  \"do_train\": true,\n","  \"do_eval\": true,\n","  \"train_batch_size\": 24,\n","  \"dev_batch_size\": 24,\n","  \"checkpoint\": 1150,\n","  \"test_batch_size\": 24,\n","  \"learning_rate\": 3e-05,\n","  \"num_train_epochs\": 15.0,\n","  \"warmup_proportion\": 0.0,\n","  \"local_rank\": -1,\n","  \"gradient_accumulation_steps\": 1,\n","  \"seed\": 8008,\n","  \"export_model\": true,\n","  \"output_name\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/my_export_models/ctb5_pos graph/real_1.bin\",\n","  \"data_sign\": \"ctb5_pos\",\n","  \"residual\": \"no\",\n","  \"training_strat\": \"bert-glyce-joint\",\n","  \"transformer\": \"yes\"\n","}\n","27595it [00:09, 2772.85it/s]\n","352it [00:00, 3621.18it/s]\n","348it [00:00, 3256.80it/s]\n","!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!\n","Please notice that the bert model if frozen\n","the loaded weights of models is \n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\n","!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!\n","\n","Training Bert...\n","######################################################################\n","EPOCH:  0\n","0it [00:00, ?it/s]/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/utils/optimization.py:142: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","1149it [15:19,  1.20it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.02332053706049919\n","100% 15/15 [00:10<00:00,  1.44it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0275 0.9663 0.9652 0.9658 0.9718\n","100% 15/15 [00:10<00:00,  1.43it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0326 0.9584 0.9592 0.9588 0.969\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [15:42,  1.22it/s]\n","######################################################################\n","EPOCH:  1\n","1149it [15:09,  1.26it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.031919267028570175\n","100% 15/15 [00:10<00:00,  1.43it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0256 0.9692 0.9689 0.969 0.9735\n","100% 15/15 [00:10<00:00,  1.43it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0323 0.9594 0.9633 0.9613 0.9694\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [15:33,  1.23it/s]\n","######################################################################\n","EPOCH:  2\n","1149it [15:08,  1.27it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.0068290154449641705\n","100% 15/15 [00:10<00:00,  1.42it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0274 0.9666 0.9674 0.967 0.9722\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [15:20,  1.25it/s]\n","######################################################################\n","EPOCH:  3\n","1149it [15:07,  1.23it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.005541509483009577\n","100% 15/15 [00:10<00:00,  1.45it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.031 0.9691 0.9681 0.9686 0.974\n","100% 15/15 [00:10<00:00,  1.43it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0442 0.9601 0.9623 0.9612 0.9705\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [15:31,  1.23it/s]\n","######################################################################\n","EPOCH:  4\n","1149it [15:10,  1.27it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.0006911874515935779\n","100% 15/15 [00:10<00:00,  1.45it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0371 0.9669 0.9681 0.9675 0.9724\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [15:21,  1.25it/s]\n","\n","Training Graph...\n","######################################################################\n","EPOCH:  5\n","1149it [11:20,  1.70it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.0008251495310105383\n","100% 15/15 [00:10<00:00,  1.42it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.038 0.9683 0.9695 0.9689 0.9732\n","100% 15/15 [00:10<00:00,  1.43it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.054 0.9598 0.9625 0.9612 0.9705\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [11:42,  1.64it/s]\n","######################################################################\n","EPOCH:  6\n","1149it [11:19,  1.72it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.004598589614033699\n","100% 15/15 [00:10<00:00,  1.42it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0387 0.968 0.969 0.9685 0.9732\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [11:30,  1.67it/s]\n","######################################################################\n","EPOCH:  7\n","1149it [11:18,  1.70it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.000470245024189353\n","100% 15/15 [00:10<00:00,  1.42it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0403 0.968 0.9689 0.9684 0.9729\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [11:29,  1.67it/s]\n","######################################################################\n","EPOCH:  8\n","1149it [11:18,  1.70it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.0004807191144209355\n","100% 15/15 [00:10<00:00,  1.44it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0419 0.9672 0.9683 0.9677 0.9725\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [11:29,  1.67it/s]\n","######################################################################\n","EPOCH:  9\n","1149it [11:20,  1.69it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.0002020199317485094\n","100% 15/15 [00:10<00:00,  1.42it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0412 0.9679 0.969 0.9685 0.9732\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [11:31,  1.66it/s]\n","\n","Training Both...\n","######################################################################\n","EPOCH:  10\n","1149it [16:19,  1.18it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.0016621348913758993\n","100% 15/15 [00:10<00:00,  1.42it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0443 0.9672 0.9699 0.9686 0.9711\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [16:30,  1.16it/s]\n","######################################################################\n","EPOCH:  11\n","1149it [16:18,  1.18it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.001396608306095004\n","100% 15/15 [00:10<00:00,  1.41it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0476 0.9675 0.9689 0.9682 0.9716\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [16:30,  1.16it/s]\n","######################################################################\n","EPOCH:  12\n","1149it [16:18,  1.18it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.002639524172991514\n","100% 15/15 [00:10<00:00,  1.41it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.05 0.9683 0.9699 0.9691 0.9726\n","100% 15/15 [00:10<00:00,  1.45it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0667 0.9577 0.9592 0.9584 0.9688\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [16:40,  1.15it/s]\n","######################################################################\n","EPOCH:  13\n","1149it [16:19,  1.16it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.00011494177306303754\n","100% 15/15 [00:10<00:00,  1.41it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0516 0.9664 0.9681 0.9673 0.9694\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [16:30,  1.16it/s]\n","######################################################################\n","EPOCH:  14\n","1149it [16:18,  1.17it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","7.722918962826952e-05\n","100% 15/15 [00:10<00:00,  1.44it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0522 0.9675 0.9695 0.9685 0.9716\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [16:30,  1.16it/s]\n","100% 15/15 [00:10<00:00,  1.42it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0704 0.9582 0.96 0.9591 0.9683\n","=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=\n","DEV: current best loss, precision, recall, f1, acc\n","0.05 0.9683 0.9699 0.9691 0.9726\n","TEST: current best loss, precision, recall, f1, acc\n","0.0442 0.9601 0.9623 0.9612 0.9705\n","=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n6tw6wYio3rR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"17f42055-f6ed-4d1a-933c-c079b1e82e07"},"source":["end = time.perf_counter()\n","elapsed = end-start\n","hours = elapsed//(60*60)\n","mins = (elapsed - hours*60*60)//60\n","secs = (elapsed - hours*60*60 - mins*60)\n","print(\"Time elapsed: %02d:%02d:%02d\" % (hours,mins,secs))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Time elapsed: 03:39:29\n"],"name":"stdout"}]}]}