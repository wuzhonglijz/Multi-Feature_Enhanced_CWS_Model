{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PKU_CWS_Graph.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"z2Id0h3kTG5F","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8d38e5b9-b509-499f-a4e0-99a395087479"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mLzXIwx9WI9f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f0fdc272-03a2-483a-889b-c89d9e4191b0"},"source":["!pip install pypinyin pywubi zhconv overrides boto3\n","!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-geometric"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pypinyin\n","  Downloading pypinyin-0.42.0-py2.py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 3.6 MB/s \n","\u001b[?25hCollecting pywubi\n","  Downloading pywubi-0.0.2-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 81.1 MB/s \n","\u001b[?25hCollecting zhconv\n","  Downloading zhconv-1.4.2.tar.gz (183 kB)\n","\u001b[K     |████████████████████████████████| 183 kB 94.7 MB/s \n","\u001b[?25hCollecting overrides\n","  Downloading overrides-6.1.0-py3-none-any.whl (14 kB)\n","Collecting boto3\n","  Downloading boto3-1.18.25-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 89.1 MB/s \n","\u001b[?25hCollecting typing-utils>=0.0.3\n","  Downloading typing_utils-0.1.0-py3-none-any.whl (10 kB)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting botocore<1.22.0,>=1.21.25\n","  Downloading botocore-1.21.25-py3-none-any.whl (7.8 MB)\n","\u001b[K     |████████████████████████████████| 7.8 MB 76.3 MB/s \n","\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 10.5 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.25->boto3) (2.8.2)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 95.9 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.25->boto3) (1.15.0)\n","Building wheels for collected packages: zhconv\n","  Building wheel for zhconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for zhconv: filename=zhconv-1.4.2-py2.py3-none-any.whl size=181081 sha256=cecc287ad97ce980b9b8fb61861e2f3638f37ebb9ab18f5c4e118eb39a4001bc\n","  Stored in directory: /root/.cache/pip/wheels/10/31/84/fca23def9be1db201eeaa76f4ee50a7d64f6e20ee7b223cc4f\n","Successfully built zhconv\n","Installing collected packages: urllib3, jmespath, botocore, typing-utils, s3transfer, zhconv, pywubi, pypinyin, overrides, boto3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.6 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.18.25 botocore-1.21.25 jmespath-0.10.0 overrides-6.1.0 pypinyin-0.42.0 pywubi-0.0.2 s3transfer-0.5.0 typing-utils-0.1.0 urllib3-1.26.6 zhconv-1.4.2\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-scatter\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_scatter-2.0.8-cp37-cp37m-linux_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 4.2 MB/s \n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.0.8\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-sparse\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_sparse-0.6.11-cp37-cp37m-linux_x86_64.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.6.11\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-cluster\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (926 kB)\n","\u001b[K     |████████████████████████████████| 926 kB 4.0 MB/s \n","\u001b[?25hInstalling collected packages: torch-cluster\n","Successfully installed torch-cluster-1.5.9\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-spline-conv\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (382 kB)\n","\u001b[K     |████████████████████████████████| 382 kB 5.0 MB/s \n","\u001b[?25hInstalling collected packages: torch-spline-conv\n","Successfully installed torch-spline-conv-1.2.1\n","Collecting torch-geometric\n","  Downloading torch_geometric-1.7.2.tar.gz (222 kB)\n","\u001b[K     |████████████████████████████████| 222 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.2)\n","Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.15)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n","Collecting rdflib\n","  Downloading rdflib-6.0.0-py3-none-any.whl (376 kB)\n","\u001b[K     |████████████████████████████████| 376 kB 34.5 MB/s \n","\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.4.7)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n","Collecting isodate\n","  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n","\u001b[K     |████████████████████████████████| 45 kB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 78.0 MB/s \n","\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.5.30)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-1.7.2-py3-none-any.whl size=388143 sha256=2bf6a58fe78454ce3defaed185d2416ca3ee7b11adff6befb33eeb4439626d99\n","  Stored in directory: /root/.cache/pip/wheels/55/93/b6/2eeb0465afe89aee74d7a07a606e9770466d7565abd45a99d5\n","Successfully built torch-geometric\n","Installing collected packages: urllib3, isodate, rdflib, torch-geometric\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.26.6\n","    Uninstalling urllib3-1.26.6:\n","      Successfully uninstalled urllib3-1.26.6\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed isodate-0.6.0 rdflib-6.0.0 torch-geometric-1.7.2 urllib3-1.25.11\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Oob8oexy_N4","outputId":"83743cca-bd37-4c98-9fed-168633b38461"},"source":["import time\n","import torch\n","print(torch.__version__)\n","print(torch.cuda.get_device_name(0))\n","start = time.perf_counter()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.9.0+cu102\n","Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AxJvcOtUTLkH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"661362c5-5a26-4f9f-b273-fec94e88ef28"},"source":["!python3 \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/bin/run_bert_graph_tagger.py\" \\\n","--data_sign pku_cws \\\n","--task_name cws \\\n","--config_path \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/configs/graph_bert.json\" \\\n","--data_dir \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/cws/pku\" \\\n","--output_name \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/my_export_models/pku_cws graph.bin\" \\\n","--bert_model \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\" \\\n","--graph_path \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/graphsDictOrder.pickle\" \\\n","--checkpoint 715 \\\n","--seed 8008 \\\n","--max_seq_length 150 \\\n","--do_train \\\n","--do_eval \\\n","--train_batch_size 24 \\\n","--dev_batch_size 24 \\\n","--test_batch_size 24 \\\n","--learning_rate 3e-5 \\\n","--num_train_epochs 15 \\\n","--gcn_hidden 300 \\\n","--k 30 \\\n","--graph_embsize 24 \\\n","--output_size 24 \\\n","--pooler_fc_size 792 \\\n","--hidden_size 792 \\\n","--transformer_hidden_size 792 \\\n","--num_features 6 \\\n","--warmup_proportion 0 \\\n","--batch_norm \"layer\" \\\n","--pretrained_graph \"yes\" \\\n","--graph_dict \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/unsupGraphModelDict300.bin\" \\\n","--training_strat \"bert-glyce-joint\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce\n","PATH to render.py\n","=*=*=*=*=*=*=*=*=*=*\n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce\n","PRINT default FONT PATH\n","********************\n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/fonts\n","********************\n","Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","Please Notice that Merge the args_dict and json_config ... ... \n","Update the config from args input\n","Update the config from args input\n","{\n","  \"glyph_ratio\": 0.1,\n","  \"glyph_decay\": 0.1,\n","  \"glyph_warmup\": 0,\n","  \"bert_frozen\": \"true\",\n","  \"hidden_size\": 792,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"classifier_sign\": \"multi_nonlinear\",\n","  \"clip_grad\": 1.0,\n","  \"bert_config\": {\n","    \"attention_probs_dropout_prob\": 0.1,\n","    \"directionality\": \"bidi\",\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.1,\n","    \"hidden_size\": 768,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"max_position_embeddings\": 512,\n","    \"num_attention_heads\": 12,\n","    \"num_hidden_layers\": 12,\n","    \"pooler_fc_size\": 768,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 3,\n","    \"pooler_size_per_head\": 128,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"type_vocab_size\": 2,\n","    \"vocab_size\": 21128\n","  },\n","  \"graph_config\": {\n","    \"hidden_dropout_prob\": 0.5,\n","    \"max_position_embeddings\": 512,\n","    \"bert_model\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\",\n","    \"graph_path\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/graphsDictOrder.pickle\",\n","    \"char2word_dim\": 0,\n","    \"char_drop\": 0.5,\n","    \"char_embsize\": 0,\n","    \"gcn_dropout\": 0.5,\n","    \"dropout\": 0.5,\n","    \"num_features\": 6,\n","    \"gcn_hidden\": 300,\n","    \"k\": 30,\n","    \"gcn_layer\": \"SAGE\",\n","    \"fc_merge\": false,\n","    \"font_channels\": 1,\n","    \"font_name\": \"cjk/NotoSansCJKsc-Regular.otf\",\n","    \"font_normalize\": false,\n","    \"font_size\": 18,\n","    \"graph_cnn_type\": \"Yuxian8\",\n","    \"graph_embsize\": 24,\n","    \"graph_groups\": 8,\n","    \"idx2char\": null,\n","    \"idx2word\": null,\n","    \"level\": \"char\",\n","    \"loss_mask_ids\": [\n","      0,\n","      101,\n","      102\n","    ],\n","    \"num_fonts_concat\": 1,\n","    \"output_size\": 24,\n","    \"pretrained_char_embedding\": \"\",\n","    \"pretrained_word_embedding\": \"\",\n","    \"random_erase\": false,\n","    \"random_fonts\": 0,\n","    \"subchar_embsize\": 512,\n","    \"subchar_type\": \"\",\n","    \"use_batch_norm\": true,\n","    \"use_highway\": false,\n","    \"use_layer_norm\": false,\n","    \"use_maxpool\": true,\n","    \"use_traditional\": false,\n","    \"word_embsize\": 1024,\n","    \"yuxian_merge\": false,\n","    \"pool\": \"sort\",\n","    \"graph_dict\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/unsupGraphModelDict300.bin\",\n","    \"pretrained_graph\": \"yes\",\n","    \"batch_norm\": \"layer\"\n","  },\n","  \"transformer_config\": {\n","    \"max_position_embeddings\": 512,\n","    \"attention_probs_dropout_prob\": 0.5,\n","    \"directionality\": \"bidi\",\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.5,\n","    \"hidden_size\": 792,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 6144,\n","    \"num_attention_heads\": 24,\n","    \"num_hidden_layers\": 2,\n","    \"pooler_fc_size\": 792,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 2,\n","    \"pooler_size_per_head\": 256,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"type_vocab_size\": 2,\n","    \"vocab_size\": 21128\n","  },\n","  \"config_path\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/configs/graph_bert.json\",\n","  \"data_dir\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/cws/pku\",\n","  \"bert_model\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\",\n","  \"task_name\": \"cws\",\n","  \"cuda\": true,\n","  \"max_seq_length\": 150,\n","  \"do_train\": true,\n","  \"do_eval\": true,\n","  \"train_batch_size\": 24,\n","  \"dev_batch_size\": 24,\n","  \"checkpoint\": 715,\n","  \"test_batch_size\": 24,\n","  \"learning_rate\": 3e-05,\n","  \"num_train_epochs\": 15.0,\n","  \"warmup_proportion\": 0.0,\n","  \"local_rank\": -1,\n","  \"gradient_accumulation_steps\": 1,\n","  \"seed\": 8008,\n","  \"export_model\": true,\n","  \"output_name\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/my_export_models/pku_cws graph/real_1.bin\",\n","  \"data_sign\": \"pku_cws\",\n","  \"residual\": \"no\",\n","  \"training_strat\": \"bert-glyce-joint\",\n","  \"transformer\": \"yes\"\n","}\n","17149it [00:13, 1309.15it/s]\n","1905it [00:01, 1437.29it/s]\n","1944it [00:01, 1362.77it/s]\n","!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!\n","Please notice that the bert model if frozen\n","the loaded weights of models is \n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\n","!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!\n","\n","Training Bert...\n","######################################################################\n","EPOCH:  0\n","0it [00:00, ?it/s]/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/utils/optimization.py:142: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","714it [09:34,  1.25it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.018737100064754486\n","100% 80/80 [00:57<00:00,  1.38it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0337 0.9771 0.9672 0.9721 0.9743\n","100% 81/81 [00:58<00:00,  1.37it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0576 0.9687 0.9526 0.9606 0.9624\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","715it [11:35,  1.03it/s]\n","######################################################################\n","EPOCH:  1\n","714it [09:29,  1.26it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.02656671032309532\n","100% 80/80 [00:57<00:00,  1.39it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0299 0.9775 0.9764 0.977 0.9786\n","100% 81/81 [00:59<00:00,  1.37it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0549 0.9697 0.963 0.9663 0.9686\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","715it [11:29,  1.04it/s]\n","######################################################################\n","EPOCH:  2\n","714it [09:28,  1.26it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.0012015384854748845\n","100% 80/80 [00:57<00:00,  1.38it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0357 0.9768 0.9771 0.9769 0.9785\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","715it [10:27,  1.14it/s]\n","######################################################################\n","EPOCH:  3\n","714it [09:27,  1.26it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.0006606350652873516\n","100% 80/80 [00:57<00:00,  1.39it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0453 0.9766 0.9788 0.9777 0.9787\n","100% 81/81 [00:58<00:00,  1.38it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0858 0.9678 0.9635 0.9656 0.9644\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","715it [11:25,  1.04it/s]\n","######################################################################\n","EPOCH:  4\n","714it [09:28,  1.27it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.0001135872516897507\n","100% 80/80 [00:57<00:00,  1.39it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0442 0.9775 0.9772 0.9774 0.9789\n","100% 81/81 [00:58<00:00,  1.38it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0835 0.9691 0.9611 0.9651 0.9633\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","715it [11:26,  1.04it/s]\n","\n","Training Graph...\n","######################################################################\n","EPOCH:  5\n","714it [07:09,  1.67it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","4.731957596959546e-05\n","100% 80/80 [00:57<00:00,  1.39it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.047 0.9776 0.9772 0.9774 0.9792\n","100% 81/81 [00:58<00:00,  1.39it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0892 0.9689 0.9611 0.965 0.9642\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","715it [09:07,  1.31it/s]\n","######################################################################\n","EPOCH:  6\n","714it [07:10,  1.65it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.00013638172822538763\n","100% 80/80 [00:57<00:00,  1.40it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0484 0.9779 0.9773 0.9776 0.9794\n","100% 81/81 [00:58<00:00,  1.38it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0933 0.9691 0.9611 0.9651 0.9638\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","715it [09:08,  1.30it/s]\n","######################################################################\n","EPOCH:  7\n","714it [07:10,  1.64it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.00018582469783723354\n","100% 80/80 [00:57<00:00,  1.39it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0483 0.9774 0.9766 0.977 0.9789\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","715it [08:08,  1.46it/s]\n","######################################################################\n","EPOCH:  8\n","714it [07:10,  1.68it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","7.168367301346734e-05\n","100% 80/80 [00:57<00:00,  1.39it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0511 0.9779 0.9765 0.9772 0.9791\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","715it [08:08,  1.46it/s]\n","######################################################################\n","EPOCH:  9\n","714it [07:10,  1.67it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","8.44871683511883e-05\n","100% 80/80 [00:57<00:00,  1.40it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0508 0.9779 0.9769 0.9774 0.9791\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","715it [08:08,  1.46it/s]\n","\n","Training Both...\n","######################################################################\n","EPOCH:  10\n","714it [10:17,  1.16it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.0022472753189504147\n","100% 80/80 [00:57<00:00,  1.39it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0502 0.9765 0.9785 0.9775 0.9785\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","715it [11:15,  1.06it/s]\n","######################################################################\n","EPOCH:  11\n","714it [10:17,  1.17it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","5.2417530241655186e-05\n","100% 80/80 [00:57<00:00,  1.40it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0524 0.9783 0.9782 0.9782 0.9788\n","100% 81/81 [00:58<00:00,  1.38it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0986 0.9697 0.9624 0.966 0.9657\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","715it [12:15,  1.03s/it]\n","######################################################################\n","EPOCH:  12\n","714it [10:15,  1.10it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.00012745519052259624\n","100% 80/80 [00:57<00:00,  1.40it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0554 0.9786 0.9782 0.9784 0.9787\n","100% 81/81 [00:58<00:00,  1.39it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.1059 0.9697 0.9618 0.9658 0.9656\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","715it [12:13,  1.03s/it]\n","######################################################################\n","EPOCH:  13\n","714it [10:17,  1.16it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","1.0357292921980843e-05\n","100% 80/80 [00:57<00:00,  1.39it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.059 0.9789 0.978 0.9785 0.9789\n","100% 81/81 [00:58<00:00,  1.38it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.1103 0.9701 0.9618 0.9659 0.9653\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","715it [12:15,  1.03s/it]\n","######################################################################\n","EPOCH:  14\n","714it [10:20,  1.09it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","2.9738308512605727e-05\n","100% 80/80 [00:58<00:00,  1.37it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0595 0.979 0.9782 0.9786 0.9788\n","100% 81/81 [00:59<00:00,  1.36it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.1118 0.9698 0.9615 0.9657 0.9652\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","715it [12:20,  1.04s/it]\n","100% 81/81 [00:59<00:00,  1.36it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.1118 0.9698 0.9615 0.9657 0.9652\n","=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=\n","DEV: current best loss, precision, recall, f1, acc\n","0.0595 0.979 0.9782 0.9786 0.9788\n","TEST: current best loss, precision, recall, f1, acc\n","0.0549 0.9697 0.963 0.9663 0.9686\n","=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n6tw6wYio3rR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a947f9cf-7fc7-4c5b-a28f-21a20c565d5e"},"source":["end = time.perf_counter()\n","elapsed = end-start\n","hours = elapsed//(60*60)\n","mins = (elapsed - hours*60*60)//60\n","secs = (elapsed - hours*60*60 - mins*60)\n","print(\"Time elapsed: %02d:%02d:%02d\" % (hours,mins,secs))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Time elapsed: 02:42:38\n"],"name":"stdout"}]}]}