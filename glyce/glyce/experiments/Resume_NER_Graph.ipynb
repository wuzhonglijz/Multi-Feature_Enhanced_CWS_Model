{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Resume_NER_Graph.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"z2Id0h3kTG5F","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b5cfde39-9688-4b19-8a82-a913a23d47a8"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mLzXIwx9WI9f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5a5a66ca-3c75-42be-8026-185fb4b11d11"},"source":["!pip install pypinyin pywubi zhconv overrides boto3\n","!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-geometric"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pypinyin\n","  Downloading pypinyin-0.42.0-py2.py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 7.7 MB/s \n","\u001b[?25hCollecting pywubi\n","  Downloading pywubi-0.0.2-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 92.3 MB/s \n","\u001b[?25hCollecting zhconv\n","  Downloading zhconv-1.4.2.tar.gz (183 kB)\n","\u001b[K     |████████████████████████████████| 183 kB 85.2 MB/s \n","\u001b[?25hCollecting overrides\n","  Downloading overrides-6.1.0-py3-none-any.whl (14 kB)\n","Collecting boto3\n","  Downloading boto3-1.18.25-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 94.1 MB/s \n","\u001b[?25hCollecting typing-utils>=0.0.3\n","  Downloading typing_utils-0.1.0-py3-none-any.whl (10 kB)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 11.3 MB/s \n","\u001b[?25hCollecting botocore<1.22.0,>=1.21.25\n","  Downloading botocore-1.21.25-py3-none-any.whl (7.8 MB)\n","\u001b[K     |████████████████████████████████| 7.8 MB 65.8 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.25->boto3) (2.8.2)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 82.7 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.25->boto3) (1.15.0)\n","Building wheels for collected packages: zhconv\n","  Building wheel for zhconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for zhconv: filename=zhconv-1.4.2-py2.py3-none-any.whl size=181081 sha256=f90952efe2e3019c08ae71b909fda36c203828898b90f94814d88e754bafaa01\n","  Stored in directory: /root/.cache/pip/wheels/10/31/84/fca23def9be1db201eeaa76f4ee50a7d64f6e20ee7b223cc4f\n","Successfully built zhconv\n","Installing collected packages: urllib3, jmespath, botocore, typing-utils, s3transfer, zhconv, pywubi, pypinyin, overrides, boto3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.6 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.18.25 botocore-1.21.25 jmespath-0.10.0 overrides-6.1.0 pypinyin-0.42.0 pywubi-0.0.2 s3transfer-0.5.0 typing-utils-0.1.0 urllib3-1.26.6 zhconv-1.4.2\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-scatter\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_scatter-2.0.8-cp37-cp37m-linux_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 7.8 MB/s \n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.0.8\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-sparse\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_sparse-0.6.11-cp37-cp37m-linux_x86_64.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 7.7 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.6.11\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-cluster\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (926 kB)\n","\u001b[K     |████████████████████████████████| 926 kB 7.9 MB/s \n","\u001b[?25hInstalling collected packages: torch-cluster\n","Successfully installed torch-cluster-1.5.9\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-spline-conv\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (382 kB)\n","\u001b[K     |████████████████████████████████| 382 kB 7.9 MB/s \n","\u001b[?25hInstalling collected packages: torch-spline-conv\n","Successfully installed torch-spline-conv-1.2.1\n","Collecting torch-geometric\n","  Downloading torch_geometric-1.7.2.tar.gz (222 kB)\n","\u001b[K     |████████████████████████████████| 222 kB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.2)\n","Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.15)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n","Collecting rdflib\n","  Downloading rdflib-6.0.0-py3-none-any.whl (376 kB)\n","\u001b[K     |████████████████████████████████| 376 kB 77.9 MB/s \n","\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.4.7)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n","Collecting isodate\n","  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n","\u001b[K     |████████████████████████████████| 45 kB 4.5 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 61.4 MB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-1.7.2-py3-none-any.whl size=388143 sha256=2364e195fbc3c15d5d682fbf1d02dbe24df69a7c2d9f587a83fdbf88b16a99e2\n","  Stored in directory: /root/.cache/pip/wheels/55/93/b6/2eeb0465afe89aee74d7a07a606e9770466d7565abd45a99d5\n","Successfully built torch-geometric\n","Installing collected packages: urllib3, isodate, rdflib, torch-geometric\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.26.6\n","    Uninstalling urllib3-1.26.6:\n","      Successfully uninstalled urllib3-1.26.6\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed isodate-0.6.0 rdflib-6.0.0 torch-geometric-1.7.2 urllib3-1.25.11\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Oob8oexy_N4","outputId":"7d50351c-a2db-49b8-ff87-e6849d384cad"},"source":["import time\n","import torch\n","print(torch.__version__)\n","print(torch.cuda.get_device_name(0))\n","start = time.perf_counter()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.9.0+cu102\n","Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AxJvcOtUTLkH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f33f89eb-ef8d-457e-d93b-5bd18836309d"},"source":["!python3 \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/bin/run_bert_graph_tagger.py\" \\\n","--data_sign resume_ner \\\n","--task_name ner \\\n","--config_path \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/configs/graph_bert.json\" \\\n","--data_dir \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/ner/resume\" \\\n","--output_name \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/my_export_models/resume_ner graph.bin\" \\\n","--bert_model \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\" \\\n","--graph_path \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/graphsDictOrder.pickle\" \\\n","--checkpoint 160 \\\n","--seed 8008 \\\n","--max_seq_length 150 \\\n","--do_train \\\n","--do_eval \\\n","--train_batch_size 24 \\\n","--dev_batch_size 24 \\\n","--test_batch_size 24 \\\n","--learning_rate 3e-5 \\\n","--num_train_epochs 15 \\\n","--gcn_hidden 300 \\\n","--k 30 \\\n","--graph_embsize 24 \\\n","--output_size 24 \\\n","--pooler_fc_size 792 \\\n","--hidden_size 792 \\\n","--transformer_hidden_size 792 \\\n","--num_features 6 \\\n","--warmup_proportion 0 \\\n","--pretrained_graph \"yes\" \\\n","--batch_norm \"layer\" \\\n","--graph_dict \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/unsupGraphModelDict300.bin\" \\\n","--training_strat \"bert-glyce-joint\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce\n","PATH to render.py\n","=*=*=*=*=*=*=*=*=*=*\n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce\n","PRINT default FONT PATH\n","********************\n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/fonts\n","********************\n","Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","Please Notice that Merge the args_dict and json_config ... ... \n","Update the config from args input\n","Update the config from args input\n","{\n","  \"glyph_ratio\": 0.1,\n","  \"glyph_decay\": 0.1,\n","  \"glyph_warmup\": 0,\n","  \"bert_frozen\": \"true\",\n","  \"hidden_size\": 792,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"classifier_sign\": \"multi_nonlinear\",\n","  \"clip_grad\": 1.0,\n","  \"bert_config\": {\n","    \"attention_probs_dropout_prob\": 0.1,\n","    \"directionality\": \"bidi\",\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.1,\n","    \"hidden_size\": 768,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"max_position_embeddings\": 512,\n","    \"num_attention_heads\": 12,\n","    \"num_hidden_layers\": 12,\n","    \"pooler_fc_size\": 768,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 3,\n","    \"pooler_size_per_head\": 128,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"type_vocab_size\": 2,\n","    \"vocab_size\": 21128\n","  },\n","  \"graph_config\": {\n","    \"hidden_dropout_prob\": 0.5,\n","    \"max_position_embeddings\": 512,\n","    \"bert_model\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\",\n","    \"graph_path\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/graphsDictOrder.pickle\",\n","    \"char2word_dim\": 0,\n","    \"char_drop\": 0.5,\n","    \"char_embsize\": 0,\n","    \"gcn_dropout\": 0.5,\n","    \"dropout\": 0.5,\n","    \"num_features\": 6,\n","    \"gcn_hidden\": 300,\n","    \"k\": 30,\n","    \"gcn_layer\": \"SAGE\",\n","    \"fc_merge\": false,\n","    \"font_channels\": 1,\n","    \"font_name\": \"cjk/NotoSansCJKsc-Regular.otf\",\n","    \"font_normalize\": false,\n","    \"font_size\": 18,\n","    \"graph_cnn_type\": \"Yuxian8\",\n","    \"graph_embsize\": 24,\n","    \"graph_groups\": 8,\n","    \"idx2char\": null,\n","    \"idx2word\": null,\n","    \"level\": \"char\",\n","    \"loss_mask_ids\": [\n","      0,\n","      101,\n","      102\n","    ],\n","    \"num_fonts_concat\": 1,\n","    \"output_size\": 24,\n","    \"pretrained_char_embedding\": \"\",\n","    \"pretrained_word_embedding\": \"\",\n","    \"random_erase\": false,\n","    \"random_fonts\": 0,\n","    \"subchar_embsize\": 512,\n","    \"subchar_type\": \"\",\n","    \"use_batch_norm\": true,\n","    \"use_highway\": false,\n","    \"use_layer_norm\": false,\n","    \"use_maxpool\": true,\n","    \"use_traditional\": false,\n","    \"word_embsize\": 1024,\n","    \"yuxian_merge\": false,\n","    \"pool\": \"sort\",\n","    \"graph_dict\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/unsupGraphModelDict300.bin\",\n","    \"pretrained_graph\": \"yes\",\n","    \"batch_norm\": \"layer\"\n","  },\n","  \"transformer_config\": {\n","    \"max_position_embeddings\": 512,\n","    \"attention_probs_dropout_prob\": 0.5,\n","    \"directionality\": \"bidi\",\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.5,\n","    \"hidden_size\": 792,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 6144,\n","    \"num_attention_heads\": 24,\n","    \"num_hidden_layers\": 2,\n","    \"pooler_fc_size\": 792,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 2,\n","    \"pooler_size_per_head\": 256,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"type_vocab_size\": 2,\n","    \"vocab_size\": 21128\n","  },\n","  \"config_path\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/configs/graph_bert.json\",\n","  \"data_dir\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/ner/resume\",\n","  \"bert_model\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\",\n","  \"task_name\": \"ner\",\n","  \"cuda\": true,\n","  \"max_seq_length\": 150,\n","  \"do_train\": true,\n","  \"do_eval\": true,\n","  \"train_batch_size\": 24,\n","  \"dev_batch_size\": 24,\n","  \"checkpoint\": 160,\n","  \"test_batch_size\": 24,\n","  \"learning_rate\": 3e-05,\n","  \"num_train_epochs\": 15.0,\n","  \"warmup_proportion\": 0.0,\n","  \"local_rank\": -1,\n","  \"gradient_accumulation_steps\": 1,\n","  \"seed\": 8008,\n","  \"export_model\": true,\n","  \"output_name\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/my_export_models/resume_ner graph/real_1.bin\",\n","  \"data_sign\": \"resume_ner\",\n","  \"residual\": \"no\",\n","  \"training_strat\": \"bert-glyce-joint\",\n","  \"transformer\": \"yes\"\n","}\n","3821it [00:01, 3384.81it/s]\n","463it [00:00, 4289.36it/s]\n","477it [00:00, 4024.57it/s]\n","!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!\n","Please notice that the bert model if frozen\n","the loaded weights of models is \n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\n","!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!\n","\n","Training Bert...\n","######################################################################\n","EPOCH:  0\n","0it [00:00, ?it/s]/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/utils/optimization.py:142: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","159it [02:05,  1.28it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.004696742165833712\n","100% 20/20 [00:13<00:00,  1.49it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0259 0.8957 0.9292 0.9121 0.9752\n","100% 20/20 [00:13<00:00,  1.44it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0277 0.9153 0.9355 0.9253 0.9793\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:34,  1.03it/s]\n","######################################################################\n","EPOCH:  1\n","159it [02:04,  1.24it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.01519299577921629\n","100% 20/20 [00:13<00:00,  1.51it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.019 0.9294 0.9405 0.9349 0.9784\n","100% 20/20 [00:13<00:00,  1.44it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0205 0.943 0.9447 0.9438 0.9791\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:34,  1.03it/s]\n","######################################################################\n","EPOCH:  2\n","159it [02:04,  1.29it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.006240169983357191\n","100% 20/20 [00:13<00:00,  1.49it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0197 0.9508 0.9546 0.9527 0.981\n","100% 20/20 [00:13<00:00,  1.46it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0257 0.9511 0.9552 0.9531 0.9815\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:33,  1.04it/s]\n","######################################################################\n","EPOCH:  3\n","159it [02:03,  1.29it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.004731346387416124\n","100% 20/20 [00:13<00:00,  1.49it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0223 0.9428 0.9466 0.9447 0.9801\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:17,  1.16it/s]\n","######################################################################\n","EPOCH:  4\n","159it [02:03,  1.29it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.0008198539144359529\n","100% 20/20 [00:13<00:00,  1.50it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0235 0.9449 0.9512 0.9481 0.9803\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:17,  1.16it/s]\n","\n","Training Graph...\n","######################################################################\n","EPOCH:  5\n","159it [01:30,  1.75it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.009557778015732765\n","100% 20/20 [00:13<00:00,  1.49it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0231 0.9429 0.9479 0.9454 0.9802\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [01:44,  1.53it/s]\n","######################################################################\n","EPOCH:  6\n","159it [01:30,  1.76it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.00018840644042938948\n","100% 20/20 [00:13<00:00,  1.48it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0221 0.945 0.9519 0.9484 0.9811\n","100% 20/20 [00:13<00:00,  1.44it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0374 0.9459 0.9453 0.9456 0.9777\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [01:58,  1.35it/s]\n","######################################################################\n","EPOCH:  7\n","159it [01:30,  1.75it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.0004223721334710717\n","100% 20/20 [00:13<00:00,  1.48it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0228 0.9443 0.9512 0.9478 0.9812\n","100% 20/20 [00:13<00:00,  1.46it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0379 0.9465 0.9459 0.9462 0.978\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [01:58,  1.35it/s]\n","######################################################################\n","EPOCH:  8\n","159it [01:31,  1.77it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.00010653305798768997\n","100% 20/20 [00:13<00:00,  1.48it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0237 0.945 0.9526 0.9488 0.9816\n","100% 20/20 [00:13<00:00,  1.44it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0387 0.9453 0.9453 0.9453 0.9784\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [01:58,  1.35it/s]\n","######################################################################\n","EPOCH:  9\n","159it [01:30,  1.74it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.00024349481100216508\n","100% 20/20 [00:13<00:00,  1.46it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.025 0.9457 0.9532 0.9494 0.9816\n","100% 20/20 [00:14<00:00,  1.40it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0391 0.9453 0.9453 0.9453 0.9785\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [01:59,  1.34it/s]\n","\n","Training Both...\n","######################################################################\n","EPOCH:  10\n","159it [02:12,  1.20it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","0.00023706810316070914\n","100% 20/20 [00:13<00:00,  1.48it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0247 0.9529 0.9586 0.9557 0.9825\n","100% 20/20 [00:13<00:00,  1.44it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0371 0.9475 0.9533 0.9504 0.9807\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:40,  1.00s/it]\n","######################################################################\n","EPOCH:  11\n","159it [02:12,  1.21it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","3.665847179945558e-05\n","100% 20/20 [00:13<00:00,  1.48it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0248 0.9555 0.9599 0.9577 0.9824\n","100% 20/20 [00:13<00:00,  1.44it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0392 0.9497 0.9509 0.9503 0.9789\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:40,  1.00s/it]\n","######################################################################\n","EPOCH:  12\n","159it [02:12,  1.21it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","7.472077413694933e-05\n","100% 20/20 [00:13<00:00,  1.47it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0272 0.9535 0.9586 0.956 0.9823\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:26,  1.09it/s]\n","######################################################################\n","EPOCH:  13\n","159it [02:12,  1.19it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","9.44282001000829e-05\n","100% 20/20 [00:13<00:00,  1.49it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0257 0.9529 0.9593 0.9561 0.9822\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:26,  1.09it/s]\n","######################################################################\n","EPOCH:  14\n","159it [02:12,  1.21it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss\n","2.856369610526599e-05\n","100% 20/20 [00:13<00:00,  1.48it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0273 0.9522 0.9586 0.9554 0.9822\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","160it [02:26,  1.09it/s]\n","100% 20/20 [00:13<00:00,  1.43it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0401 0.9486 0.9515 0.95 0.9791\n","=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=\n","DEV: current best loss, precision, recall, f1, acc\n","0.0248 0.9555 0.9599 0.9577 0.9824\n","TEST: current best loss, precision, recall, f1, acc\n","0.0257 0.9511 0.9552 0.9531 0.9815\n","=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n6tw6wYio3rR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0f2d6128-0312-44bd-c83a-a21eb1d8963c"},"source":["end = time.perf_counter()\n","elapsed = end-start\n","hours = elapsed//(60*60)\n","mins = (elapsed - hours*60*60)//60\n","secs = (elapsed - hours*60*60 - mins*60)\n","print(\"Time elapsed: %02d:%02d:%02d\" % (hours,mins,secs))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Time elapsed: 00:36:15\n"],"name":"stdout"}]}]}