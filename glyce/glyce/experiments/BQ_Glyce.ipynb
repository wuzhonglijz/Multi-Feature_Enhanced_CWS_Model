{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BQ_Glyce.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z2Id0h3kTG5F","outputId":"e3900668-163e-46f6-9207-24979b34f0d0"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mLzXIwx9WI9f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c2f95ee5-ef60-4ac8-fcf8-c88a3d3364de"},"source":["!pip install pypinyin pywubi zhconv overrides boto3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pypinyin\n","  Downloading pypinyin-0.42.0-py2.py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 15.3 MB/s \n","\u001b[?25hCollecting pywubi\n","  Downloading pywubi-0.0.2-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 78.1 MB/s \n","\u001b[?25hCollecting zhconv\n","  Downloading zhconv-1.4.2.tar.gz (183 kB)\n","\u001b[K     |████████████████████████████████| 183 kB 76.9 MB/s \n","\u001b[?25hCollecting overrides\n","  Downloading overrides-6.1.0-py3-none-any.whl (14 kB)\n","Collecting boto3\n","  Downloading boto3-1.18.3-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 54.4 MB/s \n","\u001b[?25hCollecting typing-utils>=0.0.3\n","  Downloading typing_utils-0.1.0-py3-none-any.whl (10 kB)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 8.4 MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting botocore<1.22.0,>=1.21.3\n","  Downloading botocore-1.21.3-py3-none-any.whl (7.7 MB)\n","\u001b[K     |████████████████████████████████| 7.7 MB 50.9 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.3->boto3) (2.8.1)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 63.0 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.3->boto3) (1.15.0)\n","Building wheels for collected packages: zhconv\n","  Building wheel for zhconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for zhconv: filename=zhconv-1.4.2-py2.py3-none-any.whl size=181082 sha256=4379c92885b25a4162d40b6dc4e00e0b24fa112385bf10b0e05a73705069980d\n","  Stored in directory: /root/.cache/pip/wheels/10/31/84/fca23def9be1db201eeaa76f4ee50a7d64f6e20ee7b223cc4f\n","Successfully built zhconv\n","Installing collected packages: urllib3, jmespath, botocore, typing-utils, s3transfer, zhconv, pywubi, pypinyin, overrides, boto3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.6 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.18.3 botocore-1.21.3 jmespath-0.10.0 overrides-6.1.0 pypinyin-0.42.0 pywubi-0.0.2 s3transfer-0.5.0 typing-utils-0.1.0 urllib3-1.26.6 zhconv-1.4.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7Oob8oexy_N4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0708c61b-c2a8-4ca4-ddc5-bbd8e5dc078b"},"source":["import time\n","import torch\n","print(torch.cuda.get_device_name(0))\n","start = time.perf_counter()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tesla V100-SXM2-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AxJvcOtUTLkH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f2b00e37-67d3-44bf-a712-7117cacb04c9"},"source":["!python3 \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/bin/run_bert_glyce_classifier.py\" \\\n","--data_sign bq \\\n","--task_name clf \\\n","--data_dir \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/sent_pair/bq\" \\\n","--output_name \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/my_export_models/bq glyce.bin\" \\\n","--config_path \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/configs/fudan_glyce_bert.json\" \\\n","--bert_model \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\" \\\n","--seed 8008 \\\n","--do_train \\\n","--do_eval \\\n","--checkpoint 6248 \\\n","--max_seq_length 64 \\\n","--train_batch_size 16 \\\n","--dev_batch_size 16 \\\n","--test_batch_size 16 \\\n","--learning_rate 2e-5 \\\n","--num_train_epochs 15 \\\n","--warmup_proportion 0 \\\n","--training_strat \"bert-glyce-joint\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["check the root_path of this repo\n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce\n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce\n","PATH to render.py\n","=*=*=*=*=*=*=*=*=*=*\n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce\n","PRINT default FONT PATH\n","********************\n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/fonts\n","********************\n","/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.6) or chardet (3.0.4) doesn't match a supported version!\n","  RequestsDependencyWarning)\n","Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","Please Notice that Merge the args_dict and json_config ... ... \n","Update the config from args input\n","{\n","  \"glyph_ratio\": 0.1,\n","  \"glyph_decay\": 0.1,\n","  \"glyph_warmup\": 0,\n","  \"bert_frozen\": \"true\",\n","  \"hidden_size\": 1536,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"classifier_sign\": \"single_linear\",\n","  \"bert_config\": {\n","    \"attention_probs_dropout_prob\": 0.1,\n","    \"directionality\": \"bidi\",\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.1,\n","    \"hidden_size\": 768,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"max_position_embeddings\": 512,\n","    \"num_attention_heads\": 12,\n","    \"num_hidden_layers\": 12,\n","    \"pooler_fc_size\": 768,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 3,\n","    \"pooler_size_per_head\": 128,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"type_vocab_size\": 2,\n","    \"vocab_size\": 21128\n","  },\n","  \"glyph_config\": {\n","    \"hidden_dropout_prob\": 0.5,\n","    \"max_position_embeddings\": 512,\n","    \"bert_model\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\",\n","    \"char2word_dim\": 0,\n","    \"char_drop\": 0.5,\n","    \"char_embsize\": 0,\n","    \"cnn_dropout\": 0.5,\n","    \"dropout\": 0.5,\n","    \"fc_merge\": false,\n","    \"font_channels\": 2,\n","    \"font_name\": \"cjk/NotoSansCJKsc-Regular.otf\",\n","    \"font_normalize\": false,\n","    \"font_size\": 18,\n","    \"glyph_cnn_type\": \"Yuxian8\",\n","    \"glyph_embsize\": 768,\n","    \"glyph_groups\": 8,\n","    \"idx2char\": null,\n","    \"idx2word\": null,\n","    \"level\": \"char\",\n","    \"loss_mask_ids\": [\n","      0,\n","      101,\n","      102\n","    ],\n","    \"num_fonts_concat\": 1,\n","    \"output_size\": 768,\n","    \"pretrained_char_embedding\": \"\",\n","    \"pretrained_word_embedding\": \"\",\n","    \"random_erase\": false,\n","    \"random_fonts\": 0,\n","    \"subchar_embsize\": 512,\n","    \"subchar_type\": \"\",\n","    \"use_batch_norm\": true,\n","    \"use_highway\": false,\n","    \"use_layer_norm\": false,\n","    \"use_maxpool\": true,\n","    \"use_traditional\": false,\n","    \"word_embsize\": 1024,\n","    \"yuxian_merge\": false,\n","    \"font_names\": []\n","  },\n","  \"transformer_config\": {\n","    \"max_position_embeddings\": 512,\n","    \"attention_probs_dropout_prob\": 0.5,\n","    \"directionality\": \"bidi\",\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.5,\n","    \"hidden_size\": 1536,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 6144,\n","    \"num_attention_heads\": 24,\n","    \"num_hidden_layers\": 2,\n","    \"pooler_fc_size\": 1536,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 2,\n","    \"pooler_size_per_head\": 256,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"type_vocab_size\": 2,\n","    \"vocab_size\": 21128\n","  },\n","  \"config_path\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/configs/fudan_glyce_bert.json\",\n","  \"data_dir\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/sent_pair/bq\",\n","  \"bert_model\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\",\n","  \"task_name\": \"clf\",\n","  \"cuda\": true,\n","  \"max_seq_length\": 64,\n","  \"do_train\": true,\n","  \"do_eval\": true,\n","  \"train_batch_size\": 16,\n","  \"dev_batch_size\": 16,\n","  \"checkpoint\": 6248,\n","  \"test_batch_size\": 16,\n","  \"learning_rate\": 2e-05,\n","  \"num_train_epochs\": 15.0,\n","  \"warmup_proportion\": 0.0,\n","  \"local_rank\": -1,\n","  \"gradient_accumulation_steps\": 1,\n","  \"seed\": 8008,\n","  \"nworkers\": 1,\n","  \"step\": 1,\n","  \"export_model\": true,\n","  \"output_name\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/my_export_models/bq glyce/training_1.bin\",\n","  \"data_sign\": \"bq\",\n","  \"residual\": \"no\",\n","  \"training_strat\": \"bert-glyce-joint\"\n","}\n","99999it [00:17, 5868.15it/s]\n","9999it [00:01, 6092.97it/s]\n","9999it [00:01, 6229.27it/s]\n","handling bronzeware_script/HanYiShouJinShuFan-1.ttf\n","handling Hannet.otf\n","!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!\n","Please notice that the bert model if frozen\n","the loaded weights of models is \n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\n","!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!\n","\n","Training Bert...\n","######################################################################\n","EPOCH:  0\n","0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/utils/optimization.py:142: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","6246it [23:11,  4.55it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","classification loss, glyph loss\n","0.2596428692340851 71.35954284667969\n","100% 625/625 [01:09<00:00,  8.94it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.4291 0.8491849184918492 0.8491849184918492 0.8491849184918492 0.8491849184918492\n","100% 625/625 [01:10<00:00,  8.93it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.4497 0.8407840784078408 0.8407840784078408 0.8407840784078408 0.8407840784078408\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","6250it [25:35,  4.07it/s]\n","######################################################################\n","EPOCH:  1\n","6246it [23:04,  4.48it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","classification loss, glyph loss\n","0.2849002778530121 52.336517333984375\n","100% 625/625 [01:09<00:00,  8.93it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.3898 0.8546854685468547 0.8546854685468547 0.8546854685468547 0.8546854685468547\n","100% 625/625 [01:09<00:00,  8.93it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.3957 0.8438843884388438 0.8438843884388438 0.8438843884388438 0.8438843884388438\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","6250it [25:28,  4.09it/s]\n","######################################################################\n","EPOCH:  2\n","6246it [23:00,  4.53it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","classification loss, glyph loss\n","0.01334531418979168 52.70458984375\n","100% 625/625 [01:09<00:00,  8.94it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.5111 0.8495849584958496 0.8495849584958496 0.8495849584958497 0.8495849584958496\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","6250it [24:11,  4.31it/s]\n","######################################################################\n","EPOCH:  3\n","6246it [22:53,  4.59it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","classification loss, glyph loss\n","0.021265795454382896 51.65570831298828\n","100% 625/625 [01:09<00:00,  8.94it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.5826 0.843984398439844 0.843984398439844 0.8439843984398439 0.843984398439844\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","6250it [24:04,  4.33it/s]\n","######################################################################\n","EPOCH:  4\n","6246it [22:49,  4.54it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","classification loss, glyph loss\n","0.04985122010111809 52.56743621826172\n","100% 625/625 [01:09<00:00,  8.98it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.6666 0.8456845684568457 0.8456845684568457 0.8456845684568458 0.8456845684568457\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","6250it [24:00,  4.34it/s]\n","\n","Training Glyce...\n","######################################################################\n","EPOCH:  5\n","6246it [23:26,  4.39it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","classification loss, glyph loss\n","0.004281860310584307 13.794581413269043\n","100% 625/625 [01:09<00:00,  8.93it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.8264 0.8410841084108411 0.8410841084108411 0.8410841084108411 0.8410841084108411\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","6250it [24:37,  4.23it/s]\n","######################################################################\n","EPOCH:  6\n","6246it [23:19,  4.52it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","classification loss, glyph loss\n","2.7744663384510204e-05 14.24618911743164\n","100% 625/625 [01:09<00:00,  8.94it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.9487 0.8468846884688469 0.8468846884688469 0.8468846884688469 0.8468846884688469\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","6250it [24:30,  4.25it/s]\n","######################################################################\n","EPOCH:  7\n","6246it [23:24,  4.39it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","classification loss, glyph loss\n","0.04052005708217621 16.484621047973633\n","100% 625/625 [01:09<00:00,  8.94it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.8986 0.8472847284728473 0.8472847284728473 0.8472847284728473 0.8472847284728473\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","6250it [24:35,  4.23it/s]\n","######################################################################\n","EPOCH:  8\n","6246it [23:29,  4.42it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","classification loss, glyph loss\n","0.00040061469189822674 18.747644424438477\n","100% 625/625 [01:09<00:00,  8.93it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.8926 0.8454845484548454 0.8454845484548454 0.8454845484548453 0.8454845484548454\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","6250it [24:40,  4.22it/s]\n","######################################################################\n","EPOCH:  9\n","6246it [23:31,  4.35it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","classification loss, glyph loss\n","0.00370752508752048 17.98751449584961\n","100% 625/625 [01:09<00:00,  8.94it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.9439 0.8471847184718472 0.8471847184718472 0.8471847184718472 0.8471847184718472\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","6250it [24:41,  4.22it/s]\n","\n","Training Both...\n","######################################################################\n","EPOCH:  10\n","6246it [28:05,  3.72it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","classification loss, glyph loss\n","0.0009285802370868623 18.238391876220703\n","100% 625/625 [01:09<00:00,  8.93it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.8433 0.8464846484648465 0.8464846484648465 0.8464846484648465 0.8464846484648465\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","6250it [29:16,  3.56it/s]\n","######################################################################\n","EPOCH:  11\n","6246it [27:59,  3.68it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","classification loss, glyph loss\n","3.0648527172161266e-05 20.699556350708008\n","100% 625/625 [01:09<00:00,  8.95it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","1.1527 0.8487848784878488 0.8487848784878488 0.8487848784878488 0.8487848784878488\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","6250it [29:10,  3.57it/s]\n","######################################################################\n","EPOCH:  12\n","6246it [28:05,  3.69it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","classification loss, glyph loss\n","0.00013599341036751866 19.087404251098633\n","100% 625/625 [01:09<00:00,  8.94it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","1.3026 0.8443844384438444 0.8443844384438444 0.8443844384438444 0.8443844384438444\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","6250it [29:16,  3.56it/s]\n","######################################################################\n","EPOCH:  13\n","6246it [28:02,  3.72it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","classification loss, glyph loss\n","6.482003414021165e-07 19.374731063842773\n","100% 625/625 [01:09<00:00,  8.98it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","1.4363 0.8501850185018501 0.8501850185018501 0.8501850185018501 0.8501850185018501\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","6250it [29:13,  3.56it/s]\n","######################################################################\n","EPOCH:  14\n","6246it [27:59,  3.77it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","classification loss, glyph loss\n","6.0719808061548974e-06 18.740947723388672\n","100% 625/625 [01:09<00:00,  8.94it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","1.5967 0.848984898489849 0.848984898489849 0.848984898489849 0.848984898489849\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","6250it [29:10,  3.57it/s]\n","100% 625/625 [01:09<00:00,  8.94it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","1.6802 0.8423842384238424 0.8423842384238424 0.8423842384238425 0.8423842384238424\n","=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=\n","DEV: current best loss, precision, recall, f1, acc\n","0.3898 0.8546854685468547 0.8546854685468547 0.8546854685468547 0.8546854685468547\n","TEST: current best loss, precision, recall, f1, acc\n","0.3957 0.8438843884388438 0.8438843884388438 0.8438843884388438 0.8438843884388438\n","=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n6tw6wYio3rR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e008724c-7478-4ed4-b9a3-7418409a9b37"},"source":["end = time.perf_counter()\n","elapsed = end-start\n","hours = elapsed//(60*60)\n","mins = (elapsed - hours*60*60)//60\n","secs = (elapsed - hours*60*60 - mins*60)\n","print(\"Time elapsed: %02d:%02d:%02d\" % (hours,mins,secs))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Time elapsed: 06:35:09\n"],"name":"stdout"}]}]}