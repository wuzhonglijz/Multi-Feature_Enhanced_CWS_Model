{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CTB5_POS_Combo.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"z2Id0h3kTG5F","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d8610641-849f-4186-fd58-2550b5dd1221"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mLzXIwx9WI9f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7ccf9bc0-9822-44fb-9f1b-3f2dd2b035e3"},"source":["!pip install pypinyin pywubi zhconv overrides boto3\n","!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","!pip install torch-geometric"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pypinyin\n","  Downloading pypinyin-0.42.0-py2.py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 4.1 MB/s \n","\u001b[?25hCollecting pywubi\n","  Downloading pywubi-0.0.2-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 57.4 MB/s \n","\u001b[?25hCollecting zhconv\n","  Downloading zhconv-1.4.2.tar.gz (183 kB)\n","\u001b[K     |████████████████████████████████| 183 kB 92.1 MB/s \n","\u001b[?25hCollecting overrides\n","  Downloading overrides-6.1.0-py3-none-any.whl (14 kB)\n","Collecting boto3\n","  Downloading boto3-1.18.26-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 88.3 MB/s \n","\u001b[?25hCollecting typing-utils>=0.0.3\n","  Downloading typing_utils-0.1.0-py3-none-any.whl (10 kB)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 10.9 MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting botocore<1.22.0,>=1.21.26\n","  Downloading botocore-1.21.26-py3-none-any.whl (7.8 MB)\n","\u001b[K     |████████████████████████████████| 7.8 MB 55.3 MB/s \n","\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 82.6 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.26->boto3) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.26->boto3) (1.15.0)\n","Building wheels for collected packages: zhconv\n","  Building wheel for zhconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for zhconv: filename=zhconv-1.4.2-py2.py3-none-any.whl size=181081 sha256=71be3699d74d9a362c4d6c60a6eb91308cf1b543f87b17cda6df31dd10c1e41f\n","  Stored in directory: /root/.cache/pip/wheels/10/31/84/fca23def9be1db201eeaa76f4ee50a7d64f6e20ee7b223cc4f\n","Successfully built zhconv\n","Installing collected packages: urllib3, jmespath, botocore, typing-utils, s3transfer, zhconv, pywubi, pypinyin, overrides, boto3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.6 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.18.26 botocore-1.21.26 jmespath-0.10.0 overrides-6.1.0 pypinyin-0.42.0 pywubi-0.0.2 s3transfer-0.5.0 typing-utils-0.1.0 urllib3-1.26.6 zhconv-1.4.2\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-scatter\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_scatter-2.0.8-cp37-cp37m-linux_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 3.7 MB/s \n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.0.8\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-sparse\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_sparse-0.6.11-cp37-cp37m-linux_x86_64.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.6.11\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-cluster\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (926 kB)\n","\u001b[K     |████████████████████████████████| 926 kB 3.8 MB/s \n","\u001b[?25hInstalling collected packages: torch-cluster\n","Successfully installed torch-cluster-1.5.9\n","Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n","Collecting torch-spline-conv\n","  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (382 kB)\n","\u001b[K     |████████████████████████████████| 382 kB 3.6 MB/s \n","\u001b[?25hInstalling collected packages: torch-spline-conv\n","Successfully installed torch-spline-conv-1.2.1\n","Collecting torch-geometric\n","  Downloading torch_geometric-1.7.2.tar.gz (222 kB)\n","\u001b[K     |████████████████████████████████| 222 kB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.2)\n","Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.15)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n","Collecting rdflib\n","  Downloading rdflib-6.0.0-py3-none-any.whl (376 kB)\n","\u001b[K     |████████████████████████████████| 376 kB 37.2 MB/s \n","\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.4.7)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n","Collecting isodate\n","  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n","\u001b[K     |████████████████████████████████| 45 kB 4.2 MB/s \n","\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 100.2 MB/s \n","\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-1.7.2-py3-none-any.whl size=388143 sha256=6a881e11f3cd75ed35f1963802069271b66d1469d1d0a105e1368bb9a184b907\n","  Stored in directory: /root/.cache/pip/wheels/55/93/b6/2eeb0465afe89aee74d7a07a606e9770466d7565abd45a99d5\n","Successfully built torch-geometric\n","Installing collected packages: urllib3, isodate, rdflib, torch-geometric\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.26.6\n","    Uninstalling urllib3-1.26.6:\n","      Successfully uninstalled urllib3-1.26.6\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed isodate-0.6.0 rdflib-6.0.0 torch-geometric-1.7.2 urllib3-1.25.11\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Oob8oexy_N4","outputId":"14bf68ec-79ee-462f-fe3f-9e1e03940e76"},"source":["import time\n","import torch\n","print(torch.__version__)\n","print(torch.cuda.get_device_name(0))\n","start = time.perf_counter()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.9.0+cu102\n","Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AxJvcOtUTLkH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"28d0fc70-58f4-4a90-be28-73c260fb8385"},"source":["!python3 \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/bin/run_bert_combo_tagger.py\" \\\n","--data_sign ctb5_pos \\\n","--task_name pos \\\n","--config_path \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/configs/combo_bert.json\" \\\n","--data_dir \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/pos/ctb5\" \\\n","--output_name \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/my_export_models/ctb5_pos combo.bin\" \\\n","--bert_model \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\" \\\n","--graph_path \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/graphsDictOrder.pickle\" \\\n","--checkpoint 1150 \\\n","--seed 8008 \\\n","--max_seq_length 150 \\\n","--do_train \\\n","--do_eval \\\n","--train_batch_size 24 \\\n","--dev_batch_size 24 \\\n","--test_batch_size 24 \\\n","--learning_rate 3e-5 \\\n","--num_train_epochs 15 \\\n","--gcn_hidden 300 \\\n","--k 30 \\\n","--num_features 6 \\\n","--warmup_proportion 0 \\\n","--batch_norm \"layer\" \\\n","--pretrained_graph \"yes\" \\\n","--graph_dict \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/unsupGraphModelDict300.bin\" \\\n","--training_strat \"bert-glyce-joint\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce\n","PATH to render.py\n","=*=*=*=*=*=*=*=*=*=*\n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce\n","PRINT default FONT PATH\n","********************\n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/fonts\n","********************\n","Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","Please Notice that Merge the args_dict and json_config ... ... \n","Update the config from args input\n","{\n","  \"glyph_ratio\": 0.1,\n","  \"glyph_decay\": 0.1,\n","  \"glyph_warmup\": 0,\n","  \"bert_frozen\": \"true\",\n","  \"hidden_size\": 888,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"classifier_sign\": \"multi_nonlinear\",\n","  \"bert_config\": {\n","    \"attention_probs_dropout_prob\": 0.1,\n","    \"directionality\": \"bidi\",\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.1,\n","    \"hidden_size\": 768,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"max_position_embeddings\": 512,\n","    \"num_attention_heads\": 12,\n","    \"num_hidden_layers\": 12,\n","    \"pooler_fc_size\": 768,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 3,\n","    \"pooler_size_per_head\": 128,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"type_vocab_size\": 2,\n","    \"vocab_size\": 21128\n","  },\n","  \"glyph_config\": {\n","    \"hidden_dropout_prob\": 0.5,\n","    \"max_position_embeddings\": 512,\n","    \"bert_model\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\",\n","    \"char2word_dim\": 0,\n","    \"char_drop\": 0.5,\n","    \"char_embsize\": 0,\n","    \"cnn_dropout\": 0.5,\n","    \"dropout\": 0.5,\n","    \"fc_merge\": false,\n","    \"font_channels\": 1,\n","    \"font_name\": \"cjk/NotoSansCJKsc-Regular.otf\",\n","    \"font_normalize\": false,\n","    \"font_size\": 18,\n","    \"glyph_cnn_type\": \"Yuxian8\",\n","    \"glyph_embsize\": 96,\n","    \"glyph_groups\": 8,\n","    \"idx2char\": null,\n","    \"idx2word\": null,\n","    \"level\": \"char\",\n","    \"loss_mask_ids\": [\n","      0,\n","      101,\n","      102\n","    ],\n","    \"num_fonts_concat\": 1,\n","    \"output_size\": 96,\n","    \"pretrained_char_embedding\": \"\",\n","    \"pretrained_word_embedding\": \"\",\n","    \"random_erase\": false,\n","    \"random_fonts\": 0,\n","    \"subchar_embsize\": 512,\n","    \"subchar_type\": \"\",\n","    \"use_batch_norm\": true,\n","    \"use_highway\": false,\n","    \"use_layer_norm\": false,\n","    \"use_maxpool\": true,\n","    \"use_traditional\": false,\n","    \"word_embsize\": 1024,\n","    \"yuxian_merge\": false,\n","    \"font_names\": []\n","  },\n","  \"graph_config\": {\n","    \"hidden_dropout_prob\": 0.5,\n","    \"max_position_embeddings\": 512,\n","    \"bert_model\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\",\n","    \"graph_path\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/graphsDictOrder.pickle\",\n","    \"char2word_dim\": 0,\n","    \"char_drop\": 0.5,\n","    \"char_embsize\": 0,\n","    \"gcn_dropout\": 0.5,\n","    \"dropout\": 0.5,\n","    \"num_features\": 6,\n","    \"gcn_hidden\": 300,\n","    \"k\": 30,\n","    \"gcn_layer\": \"SAGE\",\n","    \"fc_merge\": false,\n","    \"font_channels\": 1,\n","    \"font_name\": \"cjk/NotoSansCJKsc-Regular.otf\",\n","    \"font_normalize\": false,\n","    \"font_size\": 18,\n","    \"graph_cnn_type\": \"Yuxian8\",\n","    \"graph_embsize\": 24,\n","    \"graph_groups\": 8,\n","    \"idx2char\": null,\n","    \"idx2word\": null,\n","    \"level\": \"char\",\n","    \"loss_mask_ids\": [\n","      0,\n","      101,\n","      102\n","    ],\n","    \"num_fonts_concat\": 1,\n","    \"output_size\": 24,\n","    \"pretrained_char_embedding\": \"\",\n","    \"pretrained_word_embedding\": \"\",\n","    \"random_erase\": false,\n","    \"random_fonts\": 0,\n","    \"subchar_embsize\": 512,\n","    \"subchar_type\": \"\",\n","    \"use_batch_norm\": true,\n","    \"use_highway\": false,\n","    \"use_layer_norm\": false,\n","    \"use_maxpool\": true,\n","    \"use_traditional\": false,\n","    \"word_embsize\": 1024,\n","    \"yuxian_merge\": false,\n","    \"pool\": \"sort\",\n","    \"graph_dict\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/unsupGraphModelDict300.bin\",\n","    \"pretrained_graph\": \"yes\",\n","    \"batch_norm\": \"layer\"\n","  },\n","  \"transformer_config\": {\n","    \"max_position_embeddings\": 512,\n","    \"attention_probs_dropout_prob\": 0.5,\n","    \"directionality\": \"bidi\",\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.5,\n","    \"hidden_size\": 888,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3552,\n","    \"num_attention_heads\": 24,\n","    \"num_hidden_layers\": 2,\n","    \"pooler_fc_size\": 888,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 2,\n","    \"pooler_size_per_head\": 256,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"type_vocab_size\": 2,\n","    \"vocab_size\": 21128\n","  },\n","  \"config_path\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/configs/combo_bert.json\",\n","  \"data_dir\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/pos/ctb5\",\n","  \"bert_model\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\",\n","  \"task_name\": \"pos\",\n","  \"cuda\": true,\n","  \"max_seq_length\": 150,\n","  \"do_train\": true,\n","  \"do_eval\": true,\n","  \"train_batch_size\": 24,\n","  \"dev_batch_size\": 24,\n","  \"checkpoint\": 1150,\n","  \"test_batch_size\": 24,\n","  \"learning_rate\": 3e-05,\n","  \"num_train_epochs\": 15.0,\n","  \"warmup_proportion\": 0.0,\n","  \"local_rank\": -1,\n","  \"gradient_accumulation_steps\": 1,\n","  \"seed\": 8008,\n","  \"export_model\": true,\n","  \"output_name\": \"/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/my_export_models/ctb5_pos combo/real_1.bin\",\n","  \"data_sign\": \"ctb5_pos\",\n","  \"residual\": \"no\",\n","  \"training_strat\": \"bert-glyce-joint\",\n","  \"transformer\": \"yes\"\n","}\n","27595it [00:09, 2764.93it/s]\n","352it [00:00, 3716.90it/s]\n","348it [00:00, 3329.94it/s]\n","!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!!=!\n","Please notice that the bert model if frozen\n","the loaded weights of models is \n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/chinese_L-12_H-768_A-12\n","!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!!-!\n","\n","Training Bert...\n","######################################################################\n","EPOCH:  0\n","0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","/content/gdrive/MyDrive/Colab Data/Chinese Characters/glyce/glyce/utils/optimization.py:142: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","1149it [15:10,  1.22it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.05430016666650772 12.67646312713623\n","100% 15/15 [00:10<00:00,  1.41it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0231 0.97 0.9698 0.9699 0.977\n","100% 15/15 [00:10<00:00,  1.40it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0351 0.9602 0.9644 0.9623 0.972\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [15:35,  1.23it/s]\n","######################################################################\n","EPOCH:  1\n","1149it [15:01,  1.28it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.023844633251428604 11.161907196044922\n","100% 15/15 [00:10<00:00,  1.41it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0223 0.9689 0.9695 0.9692 0.9777\n","100% 15/15 [00:10<00:00,  1.40it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0322 0.9605 0.9644 0.9625 0.9708\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [15:24,  1.24it/s]\n","######################################################################\n","EPOCH:  2\n","1149it [15:00,  1.28it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.012990489602088928 11.310999870300293\n","100% 15/15 [00:10<00:00,  1.39it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0238 0.9711 0.9728 0.972 0.9783\n","100% 15/15 [00:10<00:00,  1.43it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.037 0.9593 0.964 0.9617 0.9705\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [15:22,  1.25it/s]\n","######################################################################\n","EPOCH:  3\n","1149it [15:00,  1.28it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.0071832300163805485 11.242539405822754\n","100% 15/15 [00:10<00:00,  1.39it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0259 0.9726 0.9731 0.9728 0.9798\n","100% 15/15 [00:10<00:00,  1.43it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0415 0.9616 0.9638 0.9627 0.9722\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [15:24,  1.24it/s]\n","######################################################################\n","EPOCH:  4\n","1149it [15:01,  1.28it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.008833429776132107 11.307838439941406\n","100% 15/15 [00:10<00:00,  1.39it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0314 0.9721 0.9721 0.9721 0.9773\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [15:12,  1.26it/s]\n","\n","Training Combo...\n","######################################################################\n","EPOCH:  5\n","1149it [11:28,  1.68it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.0007478733896277845 11.6973876953125\n","100% 15/15 [00:10<00:00,  1.39it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0321 0.9717 0.9724 0.972 0.9777\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [11:39,  1.64it/s]\n","######################################################################\n","EPOCH:  6\n","1149it [11:30,  1.59it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.0005858618533238769 11.723647117614746\n","100% 15/15 [00:10<00:00,  1.40it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0324 0.9706 0.9709 0.9708 0.9773\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [11:41,  1.64it/s]\n","######################################################################\n","EPOCH:  7\n","1149it [11:31,  1.68it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.00026997912209481 11.442512512207031\n","100% 15/15 [00:10<00:00,  1.38it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0332 0.9724 0.9727 0.9725 0.9784\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [11:42,  1.64it/s]\n","######################################################################\n","EPOCH:  8\n","1149it [11:29,  1.67it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.0008981646387837827 11.337346076965332\n","100% 15/15 [00:10<00:00,  1.41it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0337 0.9708 0.9717 0.9712 0.9767\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [11:41,  1.64it/s]\n","######################################################################\n","EPOCH:  9\n","1149it [11:29,  1.68it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.0011011476162821054 11.179499626159668\n","100% 15/15 [00:10<00:00,  1.39it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0353 0.9707 0.9718 0.9712 0.9771\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [11:41,  1.64it/s]\n","\n","Training Both...\n","######################################################################\n","EPOCH:  10\n","1149it [16:30,  1.16it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.000814871396869421 11.148178100585938\n","100% 15/15 [00:10<00:00,  1.38it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0342 0.9716 0.973 0.9723 0.9782\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [16:41,  1.15it/s]\n","######################################################################\n","EPOCH:  11\n","1149it [16:31,  1.14it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.00020817166659981012 11.101431846618652\n","100% 15/15 [00:10<00:00,  1.41it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0374 0.9713 0.9736 0.9724 0.9784\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [16:43,  1.15it/s]\n","######################################################################\n","EPOCH:  12\n","1149it [16:29,  1.17it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.00010533759632380679 11.18547534942627\n","100% 15/15 [00:10<00:00,  1.39it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0392 0.9733 0.9742 0.9737 0.9793\n","100% 15/15 [00:10<00:00,  1.42it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0625 0.962 0.9648 0.9634 0.9714\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [16:53,  1.13it/s]\n","######################################################################\n","EPOCH:  13\n","1149it [16:29,  1.16it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","0.00010007435776060447 11.345293998718262\n","100% 15/15 [00:10<00:00,  1.39it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0403 0.9723 0.973 0.9726 0.9782\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [16:41,  1.15it/s]\n","######################################################################\n","EPOCH:  14\n","1149it [16:29,  1.17it/s]-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","current training loss is : \n","taggging loss, glyph loss\n","4.912831718684174e-05 11.220013618469238\n","100% 15/15 [00:10<00:00,  1.41it/s]\n","............................................................\n","DEV: loss, precision, recall, f1, acc\n","0.0412 0.9727 0.9734 0.9731 0.9791\n","-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n","1150it [16:41,  1.15it/s]\n","100% 15/15 [00:10<00:00,  1.39it/s]\n","............................................................\n","TEST: loss, precision, recall, f1, acc\n","0.0699 0.9617 0.9644 0.9631 0.9718\n","=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=\n","DEV: current best loss, precision, recall, f1, acc\n","0.0392 0.9733 0.9742 0.9737 0.9793\n","TEST: current best loss, precision, recall, f1, acc\n","0.0699 0.9617 0.9644 0.9631 0.9718\n","=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n6tw6wYio3rR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2b0d0180-039e-48d5-e086-5701f922827d"},"source":["end = time.perf_counter()\n","elapsed = end-start\n","hours = elapsed//(60*60)\n","mins = (elapsed - hours*60*60)//60\n","secs = (elapsed - hours*60*60 - mins*60)\n","print(\"Time elapsed: %02d:%02d:%02d\" % (hours,mins,secs))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Time elapsed: 03:41:17\n"],"name":"stdout"}]}]}